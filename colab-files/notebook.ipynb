{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yS15NJeGmM00",
    "outputId": "2bdc1f80-5f6d-45e0-c420-a8f3ccd96a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  labels.v001.slp.training_job.zip\n",
      "  inflating: inference-script.sh     \n",
      "  inflating: jobs.yaml               \n",
      "  inflating: labels.v001.pkg.slp     \n",
      "  inflating: single_instance.json    \n",
      "  inflating: train-script.sh         \n"
     ]
    }
   ],
   "source": [
    "!unzip labels.v001.slp.training_job.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "7EfpQIoWqdr4"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7rzD7N7tqLn2"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq typing-extensions==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ao1S9hQIrFkV",
    "outputId": "30a35ebe-a795-4159-8da0-5240d433e0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rich==12.4.4\n",
      "  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m194.6/232.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rich==12.4.4) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich==12.4.4) (2.16.1)\n",
      "Installing collected packages: rich\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 11.1.0\n",
      "    Uninstalling rich-11.1.0:\n",
      "      Successfully uninstalled rich-11.1.0\n",
      "Successfully installed rich-12.4.4\n"
     ]
    }
   ],
   "source": [
    "!pip install rich==12.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "OjuJYAD8pBXE"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq numpy==1.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pK9J19FhoxxO"
   },
   "outputs": [],
   "source": [
    "!pip install -qqq pillow==9.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "S5D0h-zvnuoT"
   },
   "outputs": [],
   "source": [
    "# !pip uninstall -qqq -y opencv-python opencv-contrib-python\n",
    "!pip install -qqq sleap==\"1.3.3\"\n",
    "#pip install -qqq fastapi kaleido python-multipart uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLLOANchnw2-",
    "outputId": "b4111955-a390-43af-c4ad-98b8b13ecd5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
      "INFO:sleap.nn.training:Versions:\n",
      "SLEAP: 1.3.3\n",
      "TensorFlow: 2.8.4\n",
      "Numpy: 1.22.4\n",
      "Python: 3.10.12\n",
      "OS: Linux-5.15.120+-x86_64-with-glibc2.35\n",
      "INFO:sleap.nn.training:Training labels file: labels.v001.pkg.slp\n",
      "INFO:sleap.nn.training:Training profile: single_instance.json\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Arguments:\n",
      "INFO:sleap.nn.training:{\n",
      "    \"training_job_path\": \"single_instance.json\",\n",
      "    \"labels_path\": \"labels.v001.pkg.slp\",\n",
      "    \"video_paths\": [\n",
      "        \"./rabbit-video.mp4\"\n",
      "    ],\n",
      "    \"val_labels\": null,\n",
      "    \"test_labels\": null,\n",
      "    \"base_checkpoint\": null,\n",
      "    \"tensorboard\": false,\n",
      "    \"save_viz\": false,\n",
      "    \"zmq\": false,\n",
      "    \"run_name\": \"\",\n",
      "    \"prefix\": \"\",\n",
      "    \"suffix\": \"\",\n",
      "    \"cpu\": false,\n",
      "    \"first_gpu\": false,\n",
      "    \"last_gpu\": false,\n",
      "    \"gpu\": \"auto\"\n",
      "}\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Training job:\n",
      "INFO:sleap.nn.training:{\n",
      "    \"data\": {\n",
      "        \"labels\": {\n",
      "            \"training_labels\": null,\n",
      "            \"validation_labels\": null,\n",
      "            \"validation_fraction\": 0.1,\n",
      "            \"test_labels\": null,\n",
      "            \"split_by_inds\": false,\n",
      "            \"training_inds\": null,\n",
      "            \"validation_inds\": null,\n",
      "            \"test_inds\": null,\n",
      "            \"search_path_hints\": [],\n",
      "            \"skeletons\": []\n",
      "        },\n",
      "        \"preprocessing\": {\n",
      "            \"ensure_rgb\": true,\n",
      "            \"ensure_grayscale\": false,\n",
      "            \"imagenet_mode\": null,\n",
      "            \"input_scaling\": 1.0,\n",
      "            \"pad_to_stride\": null,\n",
      "            \"resize_and_pad_to_target\": true,\n",
      "            \"target_height\": null,\n",
      "            \"target_width\": null\n",
      "        },\n",
      "        \"instance_cropping\": {\n",
      "            \"center_on_part\": null,\n",
      "            \"crop_size\": null,\n",
      "            \"crop_size_detection_padding\": 16\n",
      "        }\n",
      "    },\n",
      "    \"model\": {\n",
      "        \"backbone\": {\n",
      "            \"leap\": null,\n",
      "            \"unet\": {\n",
      "                \"stem_stride\": null,\n",
      "                \"max_stride\": 16,\n",
      "                \"output_stride\": 2,\n",
      "                \"filters\": 16,\n",
      "                \"filters_rate\": 2.0,\n",
      "                \"middle_block\": true,\n",
      "                \"up_interpolate\": true,\n",
      "                \"stacks\": 1\n",
      "            },\n",
      "            \"hourglass\": null,\n",
      "            \"resnet\": null,\n",
      "            \"pretrained_encoder\": null\n",
      "        },\n",
      "        \"heads\": {\n",
      "            \"single_instance\": {\n",
      "                \"part_names\": null,\n",
      "                \"sigma\": 2.5,\n",
      "                \"output_stride\": 2,\n",
      "                \"loss_weight\": 1.0,\n",
      "                \"offset_refinement\": false\n",
      "            },\n",
      "            \"centroid\": null,\n",
      "            \"centered_instance\": null,\n",
      "            \"multi_instance\": null,\n",
      "            \"multi_class_bottomup\": null,\n",
      "            \"multi_class_topdown\": null\n",
      "        },\n",
      "        \"base_checkpoint\": null\n",
      "    },\n",
      "    \"optimization\": {\n",
      "        \"preload_data\": true,\n",
      "        \"augmentation_config\": {\n",
      "            \"rotate\": true,\n",
      "            \"rotation_min_angle\": -15.0,\n",
      "            \"rotation_max_angle\": 15.0,\n",
      "            \"translate\": false,\n",
      "            \"translate_min\": -5,\n",
      "            \"translate_max\": 5,\n",
      "            \"scale\": false,\n",
      "            \"scale_min\": 0.9,\n",
      "            \"scale_max\": 1.1,\n",
      "            \"uniform_noise\": false,\n",
      "            \"uniform_noise_min_val\": 0.0,\n",
      "            \"uniform_noise_max_val\": 10.0,\n",
      "            \"gaussian_noise\": false,\n",
      "            \"gaussian_noise_mean\": 5.0,\n",
      "            \"gaussian_noise_stddev\": 1.0,\n",
      "            \"contrast\": false,\n",
      "            \"contrast_min_gamma\": 0.5,\n",
      "            \"contrast_max_gamma\": 2.0,\n",
      "            \"brightness\": false,\n",
      "            \"brightness_min_val\": 0.0,\n",
      "            \"brightness_max_val\": 10.0,\n",
      "            \"random_crop\": false,\n",
      "            \"random_crop_height\": 256,\n",
      "            \"random_crop_width\": 256,\n",
      "            \"random_flip\": true,\n",
      "            \"flip_horizontal\": false\n",
      "        },\n",
      "        \"online_shuffling\": true,\n",
      "        \"shuffle_buffer_size\": 128,\n",
      "        \"prefetch\": true,\n",
      "        \"batch_size\": 4,\n",
      "        \"batches_per_epoch\": null,\n",
      "        \"min_batches_per_epoch\": 200,\n",
      "        \"val_batches_per_epoch\": null,\n",
      "        \"min_val_batches_per_epoch\": 10,\n",
      "        \"epochs\": 200,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"initial_learning_rate\": 0.0001,\n",
      "        \"learning_rate_schedule\": {\n",
      "            \"reduce_on_plateau\": true,\n",
      "            \"reduction_factor\": 0.5,\n",
      "            \"plateau_min_delta\": 1e-06,\n",
      "            \"plateau_patience\": 5,\n",
      "            \"plateau_cooldown\": 3,\n",
      "            \"min_learning_rate\": 1e-08\n",
      "        },\n",
      "        \"hard_keypoint_mining\": {\n",
      "            \"online_mining\": false,\n",
      "            \"hard_to_easy_ratio\": 2.0,\n",
      "            \"min_hard_keypoints\": 2,\n",
      "            \"max_hard_keypoints\": null,\n",
      "            \"loss_scale\": 5.0\n",
      "        },\n",
      "        \"early_stopping\": {\n",
      "            \"stop_training_on_plateau\": true,\n",
      "            \"plateau_min_delta\": 1e-08,\n",
      "            \"plateau_patience\": 10\n",
      "        }\n",
      "    },\n",
      "    \"outputs\": {\n",
      "        \"save_outputs\": true,\n",
      "        \"run_name\": \"231126_104858\",\n",
      "        \"run_name_prefix\": \"first_run\",\n",
      "        \"run_name_suffix\": \".single_instance\",\n",
      "        \"runs_folder\": \"models\",\n",
      "        \"tags\": [\n",
      "            \"\"\n",
      "        ],\n",
      "        \"save_visualizations\": true,\n",
      "        \"delete_viz_images\": true,\n",
      "        \"zip_outputs\": false,\n",
      "        \"log_to_csv\": true,\n",
      "        \"checkpointing\": {\n",
      "            \"initial_model\": false,\n",
      "            \"best_model\": true,\n",
      "            \"every_epoch\": false,\n",
      "            \"latest_model\": false,\n",
      "            \"final_model\": false\n",
      "        },\n",
      "        \"tensorboard\": {\n",
      "            \"write_logs\": false,\n",
      "            \"loss_frequency\": \"epoch\",\n",
      "            \"architecture_graph\": false,\n",
      "            \"profile_graph\": false,\n",
      "            \"visualizations\": true\n",
      "        },\n",
      "        \"zmq\": {\n",
      "            \"subscribe_to_controller\": false,\n",
      "            \"controller_address\": \"tcp://127.0.0.1:9000\",\n",
      "            \"controller_polling_timeout\": 10,\n",
      "            \"publish_updates\": false,\n",
      "            \"publish_address\": \"tcp://127.0.0.1:9001\"\n",
      "        }\n",
      "    },\n",
      "    \"name\": \"\",\n",
      "    \"description\": \"\",\n",
      "    \"sleap_version\": \"1.3.3\",\n",
      "    \"filename\": \"single_instance.json\"\n",
      "}\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Auto-selected GPU 0 with 15098 MiB of free memory.\n",
      "INFO:sleap.nn.training:Using GPU 0 for acceleration.\n",
      "INFO:sleap.nn.training:Disabled GPU memory pre-allocation.\n",
      "INFO:sleap.nn.training:System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "        Initalized: False\n",
      "     Memory growth: True\n",
      "INFO:sleap.nn.training:\n",
      "INFO:sleap.nn.training:Initializing trainer...\n",
      "INFO:sleap.nn.training:Loading training labels from: labels.v001.pkg.slp\n",
      "INFO:sleap.nn.training:Creating training and validation splits from validation fraction: 0.1\n",
      "INFO:sleap.nn.training:  Splits: Training = 18 / Validation = 2.\n",
      "INFO:sleap.nn.training:Setting up for training...\n",
      "INFO:sleap.nn.training:Setting up pipeline builders...\n",
      "INFO:sleap.nn.training:Setting up model...\n",
      "INFO:sleap.nn.training:Building test pipeline...\n",
      "INFO:sleap.nn.training:Loaded test example. [2.275s]\n",
      "INFO:sleap.nn.training:  Input shape: (720, 1280, 3)\n",
      "INFO:sleap.nn.training:Created Keras model.\n",
      "INFO:sleap.nn.training:  Backbone: UNet(stacks=1, filters=16, filters_rate=2.0, kernel_size=3, stem_kernel_size=7, convs_per_block=2, stem_blocks=0, down_blocks=4, middle_block=True, up_blocks=3, up_interpolate=True, block_contraction=False)\n",
      "INFO:sleap.nn.training:  Max stride: 16\n",
      "INFO:sleap.nn.training:  Parameters: 1,953,657\n",
      "INFO:sleap.nn.training:  Heads: \n",
      "INFO:sleap.nn.training:    [0] = SingleInstanceConfmapsHead(part_names=['left-ear', 'right-ear', 'front-left-paw', 'front-right-paw', 'back-left-paw', 'back-right-paw', 'nose', 'neck-bottom', 'tail'], sigma=2.5, output_stride=2, loss_weight=1.0)\n",
      "INFO:sleap.nn.training:  Outputs: \n",
      "INFO:sleap.nn.training:    [0] = KerasTensor(type_spec=TensorSpec(shape=(None, 360, 640, 9), dtype=tf.float32, name=None), name='SingleInstanceConfmapsHead/BiasAdd:0', description=\"created by layer 'SingleInstanceConfmapsHead'\")\n",
      "INFO:sleap.nn.training:Training from scratch\n",
      "INFO:sleap.nn.training:Setting up data pipelines...\n",
      "INFO:sleap.nn.training:Training set: n = 18\n",
      "INFO:sleap.nn.training:Validation set: n = 2\n",
      "INFO:sleap.nn.training:Setting up optimization...\n",
      "INFO:sleap.nn.training:  Learning rate schedule: LearningRateScheduleConfig(reduce_on_plateau=True, reduction_factor=0.5, plateau_min_delta=1e-06, plateau_patience=5, plateau_cooldown=3, min_learning_rate=1e-08)\n",
      "INFO:sleap.nn.training:  Early stopping: EarlyStoppingConfig(stop_training_on_plateau=True, plateau_min_delta=1e-08, plateau_patience=10)\n",
      "INFO:sleap.nn.training:Setting up outputs...\n",
      "INFO:sleap.nn.training:Created run path: models/first_run231126_104858.single_instance\n",
      "INFO:sleap.nn.training:Setting up visualization...\n",
      "Unable to use Qt backend for matplotlib. This probably means Qt is running headless.\n",
      "Unable to use Qt backend for matplotlib. This probably means Qt is running headless.\n",
      "INFO:sleap.nn.training:Finished trainer set up. [3.3s]\n",
      "INFO:sleap.nn.training:Creating tf.data.Datasets for training data generation...\n",
      "INFO:sleap.nn.training:Finished creating training datasets. [2.9s]\n",
      "INFO:sleap.nn.training:Starting training loop...\n",
      "Epoch 1/200\n",
      "2023-11-26 08:13:59.885581: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: 9 } dim { size: 360 } dim { size: 640 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -2 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14433452032 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -2 } dim { size: -5 } dim { size: -6 } dim { size: 1 } } }\n",
      "200/200 - 185s - loss: 6.7793e-05 - val_loss: 5.3167e-05 - lr: 1.0000e-04 - 185s/epoch - 927ms/step\n",
      "Epoch 2/200\n",
      "200/200 - 171s - loss: 5.3798e-05 - val_loss: 5.3405e-05 - lr: 1.0000e-04 - 171s/epoch - 854ms/step\n",
      "Epoch 3/200\n",
      "200/200 - 169s - loss: 5.3485e-05 - val_loss: 5.2142e-05 - lr: 1.0000e-04 - 169s/epoch - 843ms/step\n",
      "Epoch 4/200\n",
      "200/200 - 169s - loss: 5.3527e-05 - val_loss: 5.1217e-05 - lr: 1.0000e-04 - 169s/epoch - 843ms/step\n",
      "Epoch 5/200\n",
      "200/200 - 165s - loss: 5.3217e-05 - val_loss: 5.2392e-05 - lr: 1.0000e-04 - 165s/epoch - 825ms/step\n",
      "Epoch 6/200\n",
      "200/200 - 166s - loss: 5.3244e-05 - val_loss: 5.1160e-05 - lr: 1.0000e-04 - 166s/epoch - 832ms/step\n",
      "Epoch 7/200\n",
      "200/200 - 164s - loss: 5.3179e-05 - val_loss: 5.1412e-05 - lr: 1.0000e-04 - 164s/epoch - 821ms/step\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "200/200 - 172s - loss: 5.3473e-05 - val_loss: 5.2478e-05 - lr: 1.0000e-04 - 172s/epoch - 860ms/step\n",
      "Epoch 9/200\n",
      "200/200 - 172s - loss: 5.3085e-05 - val_loss: 5.2519e-05 - lr: 5.0000e-05 - 172s/epoch - 862ms/step\n",
      "Epoch 10/200\n",
      "200/200 - 162s - loss: 5.2763e-05 - val_loss: 5.1921e-05 - lr: 5.0000e-05 - 162s/epoch - 808ms/step\n",
      "Epoch 11/200\n",
      "200/200 - 177s - loss: 5.2920e-05 - val_loss: 5.0747e-05 - lr: 5.0000e-05 - 177s/epoch - 884ms/step\n",
      "Epoch 12/200\n",
      "200/200 - 160s - loss: 5.2847e-05 - val_loss: 5.1352e-05 - lr: 5.0000e-05 - 160s/epoch - 802ms/step\n",
      "Epoch 13/200\n",
      "200/200 - 170s - loss: 5.2710e-05 - val_loss: 5.0788e-05 - lr: 5.0000e-05 - 170s/epoch - 852ms/step\n",
      "Epoch 14/200\n",
      "200/200 - 169s - loss: 5.2412e-05 - val_loss: 5.0472e-05 - lr: 5.0000e-05 - 169s/epoch - 844ms/step\n",
      "Epoch 15/200\n",
      "200/200 - 170s - loss: 5.2089e-05 - val_loss: 5.0352e-05 - lr: 5.0000e-05 - 170s/epoch - 850ms/step\n",
      "Epoch 16/200\n",
      "200/200 - 168s - loss: 5.1130e-05 - val_loss: 4.9682e-05 - lr: 5.0000e-05 - 168s/epoch - 839ms/step\n",
      "Epoch 17/200\n",
      "200/200 - 169s - loss: 5.1103e-05 - val_loss: 5.0394e-05 - lr: 5.0000e-05 - 169s/epoch - 844ms/step\n",
      "Epoch 18/200\n",
      "200/200 - 168s - loss: 5.0867e-05 - val_loss: 4.9257e-05 - lr: 5.0000e-05 - 168s/epoch - 841ms/step\n",
      "Epoch 19/200\n",
      "200/200 - 171s - loss: 5.0147e-05 - val_loss: 4.8976e-05 - lr: 5.0000e-05 - 171s/epoch - 854ms/step\n",
      "Epoch 20/200\n",
      "200/200 - 170s - loss: 5.0432e-05 - val_loss: 4.8909e-05 - lr: 5.0000e-05 - 170s/epoch - 850ms/step\n",
      "Epoch 21/200\n",
      "200/200 - 177s - loss: 4.9643e-05 - val_loss: 4.7814e-05 - lr: 5.0000e-05 - 177s/epoch - 887ms/step\n",
      "Epoch 22/200\n",
      "200/200 - 158s - loss: 4.9282e-05 - val_loss: 4.6991e-05 - lr: 5.0000e-05 - 158s/epoch - 789ms/step\n",
      "Epoch 23/200\n",
      "200/200 - 175s - loss: 4.8582e-05 - val_loss: 4.6451e-05 - lr: 5.0000e-05 - 175s/epoch - 876ms/step\n",
      "Epoch 24/200\n",
      "200/200 - 155s - loss: 4.7444e-05 - val_loss: 4.5352e-05 - lr: 5.0000e-05 - 155s/epoch - 777ms/step\n",
      "Epoch 25/200\n",
      "200/200 - 163s - loss: 4.7081e-05 - val_loss: 4.5250e-05 - lr: 5.0000e-05 - 163s/epoch - 813ms/step\n",
      "Epoch 26/200\n",
      "200/200 - 161s - loss: 4.6479e-05 - val_loss: 4.4098e-05 - lr: 5.0000e-05 - 161s/epoch - 806ms/step\n",
      "Epoch 27/200\n",
      "200/200 - 163s - loss: 4.5331e-05 - val_loss: 4.2836e-05 - lr: 5.0000e-05 - 163s/epoch - 813ms/step\n",
      "Epoch 28/200\n",
      "200/200 - 173s - loss: 4.4963e-05 - val_loss: 4.3261e-05 - lr: 5.0000e-05 - 173s/epoch - 863ms/step\n",
      "Epoch 29/200\n",
      "200/200 - 156s - loss: 4.3735e-05 - val_loss: 4.1222e-05 - lr: 5.0000e-05 - 156s/epoch - 781ms/step\n",
      "Epoch 30/200\n",
      "200/200 - 164s - loss: 4.2912e-05 - val_loss: 4.1041e-05 - lr: 5.0000e-05 - 164s/epoch - 818ms/step\n",
      "Epoch 31/200\n",
      "200/200 - 161s - loss: 4.1858e-05 - val_loss: 3.9179e-05 - lr: 5.0000e-05 - 161s/epoch - 805ms/step\n",
      "Epoch 32/200\n",
      "200/200 - 169s - loss: 4.0332e-05 - val_loss: 3.9428e-05 - lr: 5.0000e-05 - 169s/epoch - 846ms/step\n",
      "Epoch 33/200\n",
      "200/200 - 155s - loss: 4.0041e-05 - val_loss: 3.6882e-05 - lr: 5.0000e-05 - 155s/epoch - 775ms/step\n",
      "Epoch 34/200\n",
      "200/200 - 162s - loss: 3.8677e-05 - val_loss: 3.9462e-05 - lr: 5.0000e-05 - 162s/epoch - 809ms/step\n",
      "Epoch 35/200\n",
      "200/200 - 163s - loss: 3.8193e-05 - val_loss: 3.8780e-05 - lr: 5.0000e-05 - 163s/epoch - 816ms/step\n",
      "Epoch 36/200\n",
      "200/200 - 162s - loss: 3.7562e-05 - val_loss: 3.8685e-05 - lr: 5.0000e-05 - 162s/epoch - 810ms/step\n",
      "Epoch 37/200\n",
      "200/200 - 161s - loss: 3.6827e-05 - val_loss: 3.7597e-05 - lr: 5.0000e-05 - 161s/epoch - 806ms/step\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "200/200 - 169s - loss: 3.6467e-05 - val_loss: 3.9147e-05 - lr: 5.0000e-05 - 169s/epoch - 844ms/step\n",
      "Epoch 39/200\n",
      "200/200 - 164s - loss: 3.5003e-05 - val_loss: 3.8299e-05 - lr: 2.5000e-05 - 164s/epoch - 818ms/step\n",
      "Epoch 40/200\n",
      "200/200 - 165s - loss: 3.4590e-05 - val_loss: 3.7434e-05 - lr: 2.5000e-05 - 165s/epoch - 827ms/step\n",
      "Epoch 41/200\n",
      "200/200 - 155s - loss: 3.4061e-05 - val_loss: 3.7615e-05 - lr: 2.5000e-05 - 155s/epoch - 776ms/step\n",
      "Epoch 42/200\n",
      "200/200 - 162s - loss: 3.3880e-05 - val_loss: 3.8667e-05 - lr: 2.5000e-05 - 162s/epoch - 812ms/step\n",
      "Epoch 43/200\n",
      "200/200 - 173s - loss: 3.3256e-05 - val_loss: 3.8871e-05 - lr: 2.5000e-05 - 173s/epoch - 865ms/step\n",
      "Epoch 43: early stopping\n",
      "INFO:sleap.nn.training:Finished training loop. [119.2 min]\n",
      "INFO:sleap.nn.training:Deleting visualization directory: models/first_run231126_104858.single_instance/viz\n",
      "INFO:sleap.nn.training:Saving evaluation metrics to model folder...\n",
      "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2023-11-26 10:10:20.478107: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: -42 } dim { size: -43 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -5 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14433452032 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -44 } dim { size: -45 } dim { size: 1 } } }\n",
      "\u001b[2KPredicting... \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[35m 89%\u001b[0m ETA: \u001b[36m0:00:01\u001b[0m \u001b[31m32.2 FPS\u001b[0m2023-11-26 10:10:21.315000: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: -42 } dim { size: -43 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -5 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14433452032 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -44 } dim { size: -45 } dim { size: 1 } } }\n",
      "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m5.7 FPS\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: models/first_run231126_104858.single_instance/labels_pr.train.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: models/first_run231126_104858.single_instance/metrics.train.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.164307\n",
      "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2023-11-26 10:10:24.105669: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -41 } dim { size: -42 } dim { size: -43 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -5 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14433452032 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -44 } dim { size: -45 } dim { size: 1 } } }\n",
      "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m?\u001b[0m\n",
      "\u001b[?25hINFO:sleap.nn.evals:Saved predictions: models/first_run231126_104858.single_instance/labels_pr.val.slp\n",
      "INFO:sleap.nn.evals:Saved metrics: models/first_run231126_104858.single_instance/metrics.val.npz\n",
      "INFO:sleap.nn.evals:OKS mAP: 0.151485\n"
     ]
    }
   ],
   "source": [
    "!sleap-train single_instance.json labels.v001.pkg.slp --video-paths \"./rabbit-video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvYEzErE3SWC",
    "outputId": "44e3a685-ea58-4642-bd44-48e99f610330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
      "Started inference at: 2023-11-26 10:43:33.692101\n",
      "Args:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'rabbit-video.mp4'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'models'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'/content/models/first_run231126_104858.single_instance'\u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'frames'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'only_labeled_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'only_suggested_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'output'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'no_empty_frames'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'verbosity'\u001b[0m: \u001b[32m'rich'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'video.dataset'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'video.input_format'\u001b[0m: \u001b[32m'channels_last'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'video.index'\u001b[0m: \u001b[32m''\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'cpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'first_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'last_gpu'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'gpu'\u001b[0m: \u001b[32m'auto'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'max_edge_length_ratio'\u001b[0m: \u001b[1;36m0.25\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'dist_penalty_weight'\u001b[0m: \u001b[1;36m1.0\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'open_in_gui'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'peak_threshold'\u001b[0m: \u001b[1;36m0.2\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'max_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.tracker'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.max_tracking'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.max_tracks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.target_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.pre_cull_to_target'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.pre_cull_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.post_connect_single_breaks'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.clean_instance_count'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.clean_iou_threshold'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.similarity'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.match'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.robust'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.track_window'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.min_new_track_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.min_match_points'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.img_scale'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.of_window_size'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.of_max_levels'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.save_shifted_instances'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.kf_node_indices'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'tracking.kf_init_frame_count'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "INFO:sleap.nn.inference:Auto-selected GPU 0 with 15098 MiB of free memory.\n",
      "Versions:\n",
      "SLEAP: 1.3.3\n",
      "TensorFlow: 2.8.4\n",
      "Numpy: 1.22.4\n",
      "Python: 3.10.12\n",
      "OS: Linux-5.15.120+-x86_64-with-glibc2.35\n",
      "\n",
      "System:\n",
      "GPUs: 1/1 available\n",
      "  Device: /physical_device:GPU:0\n",
      "         Available: True\n",
      "        Initalized: False\n",
      "     Memory growth: True\n",
      "\n",
      "Video: rabbit-video.mp4\n",
      "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m ETA: \u001b[36m-:--:--\u001b[0m \u001b[31m?\u001b[0m2023-11-26 10:43:38.111242: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -47 } dim { size: -48 } dim { size: -49 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -5 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14433452032 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -50 } dim { size: -51 } dim { size: 1 } } }\n",
      "\u001b[2KPredicting... \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:01\u001b[0m \u001b[31m25.4 FPS\u001b[0m2023-11-26 10:45:01.338279: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -47 } dim { size: -48 } dim { size: -49 } dim { size: 1 } } } inputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -5 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } } device { type: \"GPU\" vendor: \"NVIDIA\" model: \"Tesla T4\" frequency: 1590 num_cores: 40 environment { key: \"architecture\" value: \"7.5\" } environment { key: \"cuda\" value: \"11020\" } environment { key: \"cudnn\" value: \"8100\" } num_registers: 65536 l1_cache_size: 24576 l2_cache_size: 4194304 shared_memory_size_per_multiprocessor: 65536 memory_size: 14433452032 bandwidth: 320064000 } outputs { dtype: DT_FLOAT shape { dim { size: -5 } dim { size: -50 } dim { size: -51 } dim { size: 1 } } }\n",
      "\u001b[2KPredicting... \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m ETA: \u001b[36m0:00:00\u001b[0m \u001b[31m17.9 FPS\u001b[0m\n",
      "\u001b[?25hFinished inference at: 2023-11-26 10:45:58.290538\n",
      "Total runtime: 144.59846138954163 secs\n",
      "Predicted frames: 1789/1789\n",
      "Provenance:\n",
      "\u001b[1m{\u001b[0m\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'model_paths'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'/content/models/first_run231126_104858.single_instance/training_config.json'\u001b[0m\u001b[1m]\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'predictor'\u001b[0m: \u001b[32m'SingleInstancePredictor'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'sleap_version'\u001b[0m: \u001b[32m'1.3.3'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'platform'\u001b[0m: \u001b[32m'Linux-5.15.120+-x86_64-with-glibc2.35'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'command'\u001b[0m: \u001b[32m'/usr/local/bin/sleap-track rabbit-video.mp4 -m /content/models/first_run231126_104858.single_instance'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'data_path'\u001b[0m: \u001b[32m'rabbit-video.mp4'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'output_path'\u001b[0m: \u001b[32m'rabbit-video.mp4.predictions.slp'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'total_elapsed'\u001b[0m: \u001b[1;36m144.59846138954163\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'start_timestamp'\u001b[0m: \u001b[32m'2023-11-26 10:43:33.692101'\u001b[0m,\n",
      "\u001b[2;32m│   \u001b[0m\u001b[32m'finish_timestamp'\u001b[0m: \u001b[32m'2023-11-26 10:45:58.290538'\u001b[0m\n",
      "\u001b[1m}\u001b[0m\n",
      "\n",
      "Saved output: rabbit-video.mp4.predictions.slp\n"
     ]
    }
   ],
   "source": [
    "!sleap-track rabbit-video.mp4 -m /content/models/first_run231126_104858.single_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YS-h3K8dBUMW",
    "outputId": "655890ce-2590-444c-a7e2-a02e4b450999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n",
      "Labeled frames: 1789\n",
      "Tracks: 0\n",
      "Video files:\n",
      "  rabbit-video.mp4\n",
      "    labeled frames: 1789\n",
      "    labeled frames from 0 to 1788\n",
      "    user labeled frames: 0\n",
      "    tracks: 1\n",
      "    max instances in frame: 1\n",
      "Total user labeled frames: 0\n",
      "\n",
      "Provenance:\n",
      "  model_paths: ['/content/models/first_run231126_104858.single_instance/training_config.json']\n",
      "  predictor: SingleInstancePredictor\n",
      "  sleap_version: 1.3.3\n",
      "  platform: Linux-5.15.120+-x86_64-with-glibc2.35\n",
      "  command: /usr/local/bin/sleap-track rabbit-video.mp4 -m /content/models/first_run231126_104858.single_instance\n",
      "  data_path: rabbit-video.mp4\n",
      "  output_path: rabbit-video.mp4.predictions.slp\n",
      "  total_elapsed: 144.59846138954163\n",
      "  start_timestamp: 2023-11-26 10:43:33.692101\n",
      "  finish_timestamp: 2023-11-26 10:45:58.290538\n",
      "  args: {'data_path': 'rabbit-video.mp4', 'models': ['/content/models/first_run231126_104858.single_instance'], 'frames': '', 'only_labeled_frames': False, 'only_suggested_frames': False, 'output': None, 'no_empty_frames': False, 'verbosity': 'rich', 'video.dataset': None, 'video.input_format': 'channels_last', 'video.index': '', 'cpu': False, 'first_gpu': False, 'last_gpu': False, 'gpu': 'auto', 'max_edge_length_ratio': 0.25, 'dist_penalty_weight': 1.0, 'batch_size': 4, 'open_in_gui': False, 'peak_threshold': 0.2, 'max_instances': None, 'tracking.tracker': None, 'tracking.max_tracking': None, 'tracking.max_tracks': None, 'tracking.target_instance_count': None, 'tracking.pre_cull_to_target': None, 'tracking.pre_cull_iou_threshold': None, 'tracking.post_connect_single_breaks': None, 'tracking.clean_instance_count': None, 'tracking.clean_iou_threshold': None, 'tracking.similarity': None, 'tracking.match': None, 'tracking.robust': None, 'tracking.track_window': None, 'tracking.min_new_track_points': None, 'tracking.min_match_points': None, 'tracking.img_scale': None, 'tracking.of_window_size': None, 'tracking.of_max_levels': None, 'tracking.save_shifted_instances': None, 'tracking.kf_node_indices': None, 'tracking.kf_init_frame_count': None}\n"
     ]
    }
   ],
   "source": [
    "!sleap-inspect rabbit-video.mp4.predictions.slp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yqdFv05ETbS",
    "outputId": "0f58ddcd-9d6f-44a9-ced2-5af1245b66ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: content/models/ (stored 0%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/ (stored 0%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/labels_gt.val.slp (deflated 89%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/training_config.json (deflated 86%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/training_log.csv (deflated 59%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/labels_pr.train.slp (deflated 86%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/metrics.train.npz (deflated 1%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/initial_config.json (deflated 73%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/metrics.val.npz (deflated 2%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/best_model.h5 (deflated 6%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/labels_pr.val.slp (deflated 90%)\n",
      "  adding: content/models/first_run231126_104858.single_instance/labels_gt.train.slp (deflated 81%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r /content/file.zip /content/models/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
